<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Browse by Tag: Accessibility | Aaron Gustafson]]></title>
  <link href="https://www.aaron-gustafson.com/notebook/tags/accessibility/atom.xml" rel="self"/>
  <link href="https://www.aaron-gustafson.com/"/>
  <updated>2016-04-18T13:08:57-04:00</updated>
  <id>https://www.aaron-gustafson.com/</id>
  <author>
    <name><![CDATA[Aaron Gustafson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Web Should Just Work for Everyone]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/the-web-should-just-work-for-everyone/"/>
    <updated>2016-04-11T11:51:52-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/the-web-should-just-work-for-everyone</id>
    <content type="html"><![CDATA[<p><em>I had the great pleasure of delivering the following talk at the <a href="http://lanyrd.com/2016/edgesummit/">Edge Web Summit</a> on April 4th. The talk is largely about accessibility with a push for thinking about the future of the interface and how considering accessibility now will help us prepare for a world of “headless UIs”.</em></p>

<!-- more -->

<hr />

<p>We, as an industry, tend to have a pretty myopic view of experience. Those of us who work day-to-day in accessibility probably have a broader perspective than most, but I would argue that even we all fall short now and again when it comes to seeing the Web as others do.</p>

<p>I’m, of course, talking about accessibility. Now if you’re like most audiences, I’m guessing when you hear the word “accessibility” you probably think “screen reader”. That’s ok. Screen readers are certainly one part of the assistive technology spectrum, but my hope is, that by the end of this talk, when someone says “accessibility” you instead think… “opportunity”.</p>

<figure id="fig-2016-04-11-01" class="media-container"><img src="https://www.aaron-gustafson.com/i/posts/2016-04-11/01.gif" alt="The word “Accessibility” exploding to reveal the word “opportunity”." /></figure>

<p>Accessibility is concerned with accommodating disabilities, but our understanding of what a disability is has changed over time. In the 1980s, the World Health Organization defined a disability as a personal attribute:</p>

<blockquote>
  <p>In the context of health experience, a disability is any restriction or lack of ability (resulting from an impairment) to perform an activity in the manner or within the range considered normal for a human being.</p>
</blockquote>

<p>They have since <a href="http://www.who.int/topics/disabilities/en/">updated their definition of a disability</a> to be more context-dependent:</p>

<blockquote>
  <p>Disability is not just a health problem. It is a complex phenomenon, reflecting the interaction between features of a person’s body and features of the society in which he or she lives.</p>
</blockquote>

<p>The points of interaction between a person and society are where disability happens. It’s our responsibility to know how our designs affect these interactions.</p>

<p>If we use our own abilities and biases as a starting point, we end up with products designed for people of a specific age, language ability, tech literacy, and physical ability. Plus those with specific access to money, time, and stable network connections.</p>

<figure id="fig-2016-04-11-02" class="media-container">
{% adaptive_image /i/posts/2016-04-11/02.png %}
<figcaption>A figurative graph charting user ability against population using a bunch of different icons for people. One person is identified as a designer and she is part of a subset of the people that are in grey, signifying that they are "included" when the designer considers things from their own perspective. The vast majority of the people icons are in red, signifying they are "excluded" by this line of thinking.</figcaption>
</figure>

<p>When it comes to people, there’s no such thing as “normal”. For example, the interactions we design with technology depend heavily on what we can see, hear, say, and touch. If we’re designing with ourselves as a baseline, we can overlook people with circumstances different from ours.</p>

<p>I love exercises that create opportunities for revelation. One of my favorites originates from <a href="https://en.wikipedia.org/wiki/John_Rawls">John Rawls</a>. Rawls was a philosopher who used to run a social experiment with students, church groups, and the like. In the experiment, individuals were allowed to create their ideal society. It could follow any philosophy. It could be a monarchy or democracy or anarchy. It could be capitalist or socialist. The people in this experiment had free rein to control absolutely every facet of the society… but then he’d add the twist: They could not control what position they occupied in that society.</p>

<p>This twist is what <a href="https://en.wikipedia.org/wiki/John_Harsanyi">John Harsanyi</a>—an early game theorist—refers to as the <a href="https://en.wikipedia.org/wiki/Veil_of_ignorance">“Veil of Ignorance”</a> and what Rawls found, time and time again, was that individuals participating in the experiment would gravitate toward creating the most egalitarian societies.</p>

<p>It makes sense: what rational, self-interested human being would treat the elderly, the sick, people of a particular gender or race or creed or color, poorly if they could find themselves in that position?</p>

<p>We’re often told accessibility is only concerned with folks with “special needs.” Well news flash: <em>we all have special needs</em>. Some we’re born with. Some we develop. Some are temporary. Some have nothing to do with us personally, but are situational or purely dependent on the hardware we are using, the interaction methods we have available to us, or even the speed at which we can access the Internet or process data.</p>

<p>Sometimes disability is a temporary thing. A short-term injury and illness affect the way people interact with the world around them. Looking into bright light can cause brief visual impairment. Being sick with a cough makes it hard to speak. Wearing a cast can severely limit a person’s ability to lift an everyday object.</p>

<p>On the more technical side of things, small touchscreens can be awkward to interact with is you’re fat-fingered like me. Glossy screens can be difficult to read under glaring light. Low-contrast text can be difficult to read when you turn the screen brightness down to conserve battery life on your mobile device.</p>

<p>Recognizing that we all have special needs leads us to make better decisions as designers and developers. When we understand that disability is a universal and dynamic way of interacting with the world, it can become something else as well: a new source for creativity. Our impact can also expand, as our inclusive designs reach a greater number of people.</p>

<p>Designing for people with permanent disabilities can seem like a significant constraint, but the resulting designs can actually benefit a much larger number of people. For example, curb cuts in sidewalks were first created to make it safer and easier for people in wheelchairs to cross the street.</p>

<figure id="fig-2016-04-11-03" class="media-container">
{% adaptive_image /i/posts/2016-04-11/03.jpg %}
<figcaption>A curb cut. <b class="media-container__credit">Photo credit: <a href="https://www.flickr.com/photos/12155320@N00/6793281764/">Dylan Passmore</a></b></figcaption>
</figure>

<p>But curb cuts also help people with a wide range of circumstances, from kids riding bicycles, to parents pushing strollers, to workers hauling heavy equipment.</p>

<figure id="fig-2016-04-11-04" class="media-container">
{% adaptive_image /i/posts/2016-04-11/04.png alt="Numerous needs that benefit from curb cuts: wheelchairs, strollers, bicycles, and skateboards." %}
</figure>

<p>Similarly, high-contrast screen settings were initially made to benefit people with vision impairments. But today, many people benefit from high-contrast settings when they use a device in bright sunlight. The same is true for remote controls, automatic door openers, voice controls, and much more. Designing with constraints in mind is simply designing well.</p>

<figure id="fig-2016-04-11-05" class="media-container">
{% adaptive_image /i/posts/2016-04-11/05.png alt="A disability continuum from permanent (a person with one arm) to temporary (a person with an arm injury) to situational (a new parent holding a baby)." %}
</figure>

<p>By designing for someone with a permanent disability, someone with a situational disability can also benefit. For example, a device designed for a person who has one arm could be used just as effectively by a person with a temporary wrist injury or a new parent holding an infant.</p>

<figure id="fig-2016-04-11-06" class="media-container">
{% adaptive_image /i/posts/2016-04-11/06.png alt="Adding up the number of people in the U.S. who deal with disabilities relating to arm usage gets your to 21 million pretty quickly." %}
</figure>

<p>Being mindful of the continuum from permanent to situational disabilities helps us rethink how our designs can scale to more people in new ways. In the United States, 26,000 people a year suffer from loss of upper extremities.</p>

<p>But when we include people with temporary and situational disabilities, the number is greater than 20M.</p>

<p>As a web design philosophy, progressive enhancement is right in line with the egalitarian inclusive design approach. It calls for equality of opportunity, but doesn’t require equality of outcome. It’s okay for different folks to experience your products in different ways as long as everyone can accomplish the task they set out to do.</p>

<p>As <a href="http://benhoh.com/journal/2012/01/30/from-degradation-to-enhancement">Ben Hoh eloquently put it</a></p>

<blockquote>
  <p>[Progressive enhancement] keeps the design open to the possibilities of sexiness in opportune contexts, rather than starting with the ‘whole’ experience that must be compromised.</p>
</blockquote>

<p>At its essence, progressive enhancement is about being good designers. The definition of design is “to devise for a specific function or end” Classically, it means “to indicate” and comes from the medieval Latin: <i lang="la">designare</i>, meaning “to mark out”.</p>

<blockquote>
  <p>I’ve been amazed at how often those outside the discipline of design assume that what designers do is decoration—likely because so much bad design simply is decoration. Good design isn’t. Good design is problem solving.</p>
</blockquote>

<p>As Jeff Veen so astutely observed in <a href="http://www.inspireux.com/2009/01/19/good-design-isnt-decoration-good-design-is-problem-solving/">this quote</a>, there is a lot of bad “design” out there that is more concerned with aesthetics than problem solving.</p>

<p>When we are concerned with the user interface, it can sometimes be at the expense of the user experience.</p>

<figure id="fig-2016-04-11-07" class="media-container">
{% adaptive_image /i/posts/2016-04-11/07.png %}
<figcaption>The <a href="http://impossibleobjects.com/coffeepot-for-masochists.html">Coffeepot for Masochists by Jaques Carelman</a> famously referenced by Donald Norman in <a href="http://amzn.to/1RP2vB9"><cite>Emotional Design</cite></a>.</figcaption>
</figure>

<p>It is possible to have something both beautiful and highly functional.</p>

<figure id="fig-2016-04-11-08" class="media-container">
{% adaptive_image /i/posts/2016-04-11/08.jpg %}
<figcaption>A ramp embedded in staircase of <a href="https://en.wikipedia.org/wiki/Robson_Square">Robson Square</a> in Vancouver, <abbr aria-label="British Columbia">BC</abbr>. <b class="media-container__credit">Photo credit: <a href="https://www.flickr.com/photos/mag3737/">Tom Magliery</a></b></figcaption>
</figure>

<p><a href="https://24ways.org/">24 Ways</a> is an advent calendar for web professionals. It’s a magazine of sorts, but it is both highly interactive and accessible. The site’s developers employ a handful of features from <a href="https://www.w3.org/TR/wai-aria/">the ARIA spec</a> to increase the accessibility of the site.</p>

<p>One such feature is <a href="https://www.w3.org/WAI/GL/wiki/Using_ARIA_landmarks_to_identify_regions_of_a_page">ARIA landmarks</a>, which identify key areas of a web page. Such as the primary header or “banner” of a site.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 banner.html embed %}</p>

<p>The main content.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 main.html embed %}</p>

<p>Content concerned with easing navigation of the site.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 navigation.html embed %}</p>

<p>Or even information about the content, such as copyright designations.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 contentinfo.html embed %}</p>

<p>Users browsing with an ARIA-aware screen reader can use these landmarks to quickly navigate through a document.</p>

<figure id="figure-2016-04-11-09">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.mp3" type="audio/mpeg;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-04-11/09.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>This example hints at a simple reality: <strong>Every interface is a conversation</strong>. We engage our users directly in an effort to inform them, entertain them, or persuade them to act in a particular way. How this conversation goes directly affects the experience our users have.</p>

<p>Now this may sound great as a quote to share on Twitter—feel free—but it’s absolutely true. And it’s going to become even more important that we pay attention to this conversation as personal assistants—you know, “assistive technology”, it’s right there in the name—begins to play a larger part in our users’ lives.</p>

<p>We need to consider the experience when our products are stripped to their essence. When there is no visual design to entice our users to overlook the fundamental flaws in the design of our interfaces. When there is no UI to help them manage the cognitive load of accomplishing a given task.</p>

<p>Considering this now will put you way ahead of your competition and empower your users to do more with your products. It can seem like a daunting task when we’ve spent so much time fixated on how to enable our users to accomplish key tasks on a screen, especially in a responsive context. But what is responsive design about if not accessibility? Responsive design is concerned with presenting the most appropriate visual experience given the constraints of a screen’s size.</p>

<p>Similarly, conversational interfaces are concerned with the way we communicate with our users, whether there is a screen or not and whether the user can see it or not. This isn’t new, it’s a challenge we’ve tackled before…</p>

<p>Let’s take a trip back in time to one of the earliest computer games: Zork. Zork was written between 1977 and 1979. It’s a text-based adventure game that operates a lot like a game of <em>Dungeons &amp; Dragons</em>—with the program serving the role of gamemaster.</p>

<p>As you move from location to location throughout the game, the program describes the environment and notes objects and people you can interact with. You type what you want to do and the program tells you the results of your actions.</p>

<blockquote>
  <p>West of House<br /> You are standing in an open field west of a white house, with a boarded front door.<br /> There is a small mailbox here.<br /><br />&gt; <strong>open mailbox</strong></p>
</blockquote>

<p>As this was the early days of computer gaming, you might think Zork’s interactions would be simple noun-verb combinations—”kill troll”—but Zork was more sophisticated than that. Its parser was could understand far more complex commands like “hit the troll with the Elvish sword”. This made the experience far more natural, as if you were playing a table top game with friends.</p>

<p>Whether Zork or a webpage, <strong>every interface is a conversation</strong>. When I create a homepage, I’m talking to visitors as if we’ve just met. I’m explaining what they can do on my site (and, in some cases, why it matters). If I’m designing a product page, the conversation is a little different. I’m explaining to my users what a particular object or service is, what it does, and how it will benefit them. I’ll skip the BS sales pitch and talk honestly about the product’s benefits. If I’m designing a contact form, I want to help my users get a message to me quickly and efficiently. I’m also going to set some expectations around how long it will take me to get back to them (and, of course, I’ll need to abide by that promise). Even the humble status update is a conversation. I’m asking a question and then stepping back and letting my users speak. The floor is theirs. (But I’m probably mining what they say for data so I can market to them later.)</p>

<p>Conversations consist of words, so it should come as no surprise that we should choose our words carefully. When talking to people, things generally go better when you talk to them like they talk to you. This is a lesson Facebook learned the (somewhat) hard way.</p>

<p>Over the 2011 holidays, Facebook users were uploading photos like crazy. In the span of a few days, Facebook processed more photo uploads than are contained in the entirety of Flickr. Seriously, that’s a lot of photos.</p>

<p>One unintended consequence of this deluge of photo uploads was a significant uptick in people asking Facebook to remove specific ones. Facebook received millions of these “photo reports”, but they made no sense: Moms holding babies reported for harassment, pictures of puppies reported for hate speech, and so on. Roughly 97% of these photo reports were dramatically mis-categorized.</p>

<p>Facebook’s engineers reached out to some of the users who had reported these photos to get a bit more background regarding their submissions.</p>

<p>At the time Facebook’s photo reporting interface provided a list of reasons users could choose from if they wanted a photo removed, but, as Facebook soon discovered, many of the reports were made because users didn’t want the photo posted for reasons other than those provided.</p>

<p>In some cases, it was because they didn’t like how they looked in the photo. In others, it was because the photo was of an ex-partner or even a beloved pet they’d shared with an ex-boyfriend or ex-girlfriend. The existing photo reporting tool had not done a good job of accounting for these more personal reasons for wanting a photo removed, so the Facebook engineers went to work. They added a step that asked <em>How does this photo make you feel?</em> The options were simple:</p>

<ul>
  <li>Embarrassing</li>
  <li>Upsetting</li>
  <li>Saddening</li>
  <li>Bad Photo</li>
  <li>Other</li>
</ul>

<p>The “other” option also provided a free-response text field to fill in.</p>

<p>With this system in place, they found that 50% of reporters who answered the new question chose one of the provided options. That was pretty helpful, but there was still a problem: 34% of the “other” respondents were writing “It’s embarrassing” in the blank rather than choosing the “embarrassing” option already provided.</p>

<p>What the Facebook team realized was that people were not identifying with the “embarrassing” text (or may have even thought it was referring to them, rather than assuming an implied “It’s”). A subtle shift in language was needed, so they changed the label to <em>Please describe the photo</em> and they updated the options to mirror how people actually talk:</p>

<ul>
  <li>It’s embarrassing</li>
  <li>It’s a bad photo of me</li>
  <li>It makes me sad</li>
</ul>

<p>With this subtle change, they were able to increase the percentage of photo reporters who chose one of the options provided to a whopping 78%.</p>

<p>Words matter. Even in something as simple and banal as a form, the words we choose set the tone for our users’ experiences and often have an affect on what they do… or fail to do. The words we choose matter even more in the world of headless UIs. Without visual aids to help a user see where they are in a form or to aid them in managing the cognitive load of our interfaces, every bit of label and helper text becomes even more important.</p>

<p>When Luke Wroblewski coined “mobile first”, he told us to focus on the core purpose each and every page. He was, in essence, telling us to focus on the conversation we are having with our users. This approach pays huge dividends on small screens, but when it comes to voice-based interactions, “the page” doesn’t really exist. Experience is the sum of each individual interaction.</p>

<p>As part of their Alexa Skills Kit, Amazon offers a ton of recommendations for designing for voice, many of which happen to be equally useful for sighted users.</p>

<h2 id="write-for-people">Write for People</h2>

<p>We don’t author content for ourselves. We write for others. If what we write frustrated or alienates our users, we’ve failed at our job. In their profoundly helpful book <a href="http://amzn.to/1YpYLq1"><cite>Nicely Said</cite></a>, Nicole Fenton and Kate Kiefer Lee offer numerous suggestions for how to write with the reader in mind:</p>

<ul>
  <li>Be clear.</li>
  <li>Be concise.</li>
  <li>Be honest.</li>
  <li>Be considerate.</li>
  <li>Write how you speak.</li>
</ul>

<p>They also make the recommendation that you read your work aloud. As we head into the world of voice-based interactions, that’s beta testing!</p>

<h2 id="avoid-technical-and-legal-jargon">Avoid Technical and Legal Jargon</h2>

<p>For example, if you track error codes for issues on your site, send them to <em>your developers</em>, but never present them to a user. Similarly, we should avoid legalese and write in plain language. Medium has done a great job of this with <a href="https://medium.com/policy/medium-terms-of-service-9db0094a1e0f#.mgexdk816">their Terms of Service</a>.</p>

<h2 id="when-requesting-feedback-make-it-clear-that-the-user-needs-to-respond">When Requesting Feedback, Make It Clear That the User Needs to Respond</h2>

<p>In perhaps the most common form example, consider the label “First Name”. It’s not terribly conversational and doesn’t beg for a response.</p>

<p>{% gist 6f5b7c0f0c072631a908 better-labels.html %}</p>

<figure id="figure-2016-03-04-05">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3" type="audio/mpeg;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>Similarly, when there’s an error, notify them of the error and, if possible, give them some clues on how to fix it.</p>

<p>{% gist 6f5b7c0f0c072631a908 field-error.html %}</p>

<figure id="figure-2016-03-04-06">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<h2 id="when-asking-a-user-to-choose-clearly-present-the-options">When Asking a User to Choose, Clearly Present the Options</h2>

<p>This comes into play often when dealing with forms. Ensuring radio and checkbox controls are properly associated with their labels is critical.</p>

<p>{% gist 6f5b7c0f0c072631a908 radio-label.html %}</p>

<p>You can also use the <code>fieldset</code> and <code>legend</code> elements to group the related controls, but be sure to make the <code>legend</code> focusable or associate it with the first focusable form control in order to ensure the question is read out.</p>

<p>{% gist 6f5b7c0f0c072631a908 fieldset.html %}</p>

<figure id="figure-2016-03-04-07">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>We should strive for the same sort of clarity when presenting navigation options. The HTML5 <code>nav</code> element enables us to semantically identify an area of the page being used for navigation. It is not, however, always identified as being navigation when encountered naturally in the flow of the document. (It is when using role-based navigation like we saw earlier.) For that reason, it can be useful to provide an textual introduction to the section, even if you choose to visibly hide it. You might even consider expanding the text of your navigation items to provide additional context like I do on my site.</p>

<p>{% gist 6f5b7c0f0c072631a908 navigation.html %}</p>

<figure id="figure-2016-03-04-08">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p><a href="http://www.npr.org/">NPR</a> has multiple navigation elements on the page and they use ARIA to label them without adding additional tags. Instead, they use the <code>aria-label</code> attribute to distinguish them.</p>

<p>{% gist 9b3c92fec79342edc9400b48ecaa0cb8 aria-label.html embed %}</p>

<h2 id="prompts-should-be-short-while-still-being-clear">Prompts Should be Short, While Still Being Clear</h2>

<p>In <a href="https://www.stmarys-ca.edu/sites/default/files/attachments/files/On_The_Method_of_Theoretical_Physics.pdf">a 1933 lecture at Oxford</a>, Albert Einstein famously said</p>

<blockquote>
  <p>It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.</p>
</blockquote>

<p>Or, as <a href="https://books.google.com/books?id=prDfAFjet9cC&amp;lpg=PR7&amp;ots=PA9rRog4cr&amp;dq=How%20a%20%E2%80%98Difficult%E2%80%99%20Composer%20Gets%20That%20Way&amp;pg=PA230#v=onepage&amp;q&amp;f=false">Roger Sessions paraphrased it</a></p>

<blockquote>
  <p>Everything should be as simple as it can be but not simpler.</p>
</blockquote>

<p>Clear and concise writing is the hallmark of great content. We need to resist the urge to write for writing’s sake. We write in the service our audience, not for ourselves.</p>

<p>Government websites are some of the worst offenders in this area. Consider this lovely passage:</p>

<blockquote>
  <p>Heavy rains throughout most of the State have given an optimistic outlook for lessened fire danger for the rest of the season. However, an abundance of lightning maintains a certain amount of hazard in isolated areas that have not received an excessive amount of rain.</p>
</blockquote>

<p>It could be written far more clearly as</p>

<blockquote>
  <p>Heavy rains throughout most of the State have lessened fire danger for the rest of the season. However, lightning threatens isolated dry areas.</p>
</blockquote>

<p>In the UK, the Government Digital Service has made great strides overhauling excruciatingly painful content and making it easier to read and understand. One such example is <a href="https://gds.blog.gov.uk/2014/07/28/doing-the-hard-work-to-make-things-simple/">their overhaul of the Accelerated Possession process</a> that allows landlords to evict a tenant.</p>

<p>The original paper form asked for the address like this</p>

<blockquote>
  <p>The claimant seeks an order that the defendant(s) give possession of:<br /> (If the premises of which you seek possession are part of a building identify the part eg. Flat 3, Rooms 6 and 7)</p>
</blockquote>

<p>Before requesting the type of property concerned</p>

<blockquote>
  <p>(‘the premises’) which is<br /> ☐ a dwelling house<br /> ☐ part of a dwellinghouse</p>
</blockquote>

<figure id="figure-2016-03-04-09">
{% adaptive_image /i/posts/2016-03-04/09.png %}
</figure>

<p>Clear and to the point, right?</p>

<p>The GDS went to work and streamlined the process in plain language:</p>

<blockquote>
  <p>What kind of property do you want to take back?<br /> ◎ A self-contained house, flat or bedsit<br /> ◎ Room or rooms in a property.<br /> Tenants may share kitchen or bathroom</p>
</blockquote>

<p>Then they allow you to lookup the property or manually enter the address.</p>

<figure id="figure-2016-03-04-10">
{% adaptive_image /i/posts/2016-03-04/10.png %}
</figure>

<p>While not specifically designed for the future of headless UIs, this form is prepared for their eventuality.</p>

<h2 id="ask-only-necessary-questions">Ask Only Necessary Questions</h2>

<p>We show our users respect by respecting their time. Obviously straightforward, brief writing is one way we do that, but another is to reduce the time it takes to complete a task. Many forms are brimming with fields to be filled in. In some cases, the vast majority are purely optional. And while it may be easy to spot the required fields visually, bypassing them in an aural interface can be incredibly difficult.</p>

<figure id="figure-2016-03-04-11">
{% adaptive_image /i/posts/2016-03-04/11.jpg %}
</figure>

<p>User experience designers have been pushing for simplified forms since… well, as long as I can remember. Users appreciate them, they tend to result in better data, and they also tend to convert better than long forms. And when it comes to voice-based interactions, they will become a necessity. No one is going to want to spend 15 minutes working their way through a 15 question registration form when all that’s required is their email address and for them to choose a password.</p>

<figure id="figure-2016-03-04-12">
{% adaptive_image /i/posts/2016-03-04/12.jpg %}
</figure>

<p>On a similar note, we should avoid slicing fields into multiple parts if at all possible. For instance, you still see fields like this one, asking for a US phone number, quite often:</p>

<figure id="figure-2016-03-04-13">
{% adaptive_image /i/posts/2016-03-04/13.png %}
</figure>

<p>When interacting with this construct via voice, a user will be required to supply three separate values. In order to do so, each field would require a label. Most developers only know how to label the first of those three boxes and users would be really confused if you asked them for their exchange code and line number.</p>

<p>HTML5 introduced a host of new field types that consolidate phone numbers, dates, times, and other complex data types into single fields. Use them! As an added bonus, most enforce content validation and formatting rules for you automatically.</p>

<h3 id="present-information-in-consumable-pieces">Present Information in Consumable Pieces</h3>

<p>Like computers, we humans have a finite amount of “working memory”. The amount of mental resources required to operate an interface is called its “cognitive load”. When the amount of information we need to process exceeds our capacity to handle it, we can miss important details, have trouble concentrating, and become frustrated.</p>

<p>We deal with cognitive load in GUI design all the time, but in voice-based interactions, there are no visuals to act as signposts and provide reminders about where we are and what we’re doing. This is why it is critical to break complicated tasks down into simpler ones and eliminate excess noise (like non-required fields). We can also reduce cognitive load by chunking search results and other list-type content into small groups, asking the user if they want more before loading and presenting them.</p>

<blockquote>
  <p>The top seller in the garden department is Repel Lemon Eucalyptus Natural Insect Repellent, 4-Ounce Pump Spray</p>
</blockquote>

<blockquote>
  <p>Would you like to hear the rest?</p>
</blockquote>

<hr />

<p>As human beings, we all have special needs, but as designers and developers, it can sometimes be difficult to diagnose potential issues within our products when it comes to accessibility. Especially if we don’t typically experience that need or are unfamiliar with the tools used to address it.</p>

<p>To that end, my colleagues have been hard at work to make it easier to enhance the accessibility of our products. The first tool I want to discuss is the F12 developer tools in Edge.</p>

<p>As Andy Sterland mentioned in his talk, in a forthcoming release of F12, the inspector will surface accessibility information about each node in the DOM. Let’s take a look at an example:</p>

<p>{% youtube Z0PSK4IUAVM %}</p>

<p>Here we have the forthcoming redesign of <a href="http://html5accessibility.com/">HTML5accessibility.com</a> and if I inspect the section containing the test results, I can see information about that section element. On the right hand side, you’ll notice an inspector tab dedicated to accessibility information such as the node’s accessible name, it’s role, whether it’s keyboard focusable, ARIA properties assigned to it (in this case, <code>aria-label</code>), and so on.</p>

<p>Adding this functionality into F12 lifts the veil from the way Edge exposes the DOM to assistive technology and will go a long way toward helping us fine tune our experiences for <abbr aria-label="assistive technology">AT</abbr>, including screen readers and virtual assistants.</p>

<p>Another area where we are doing some work is within Narrator itself. When testing with screen readers, it can be quite tempting as a sighted user, to leave your screen on so you can follow along. Sadly, that action directly prohibits you from experiencing a site or application the way folks with visual impairments or in a headless UI scenario do. It can cause you to miss things or assume something makes sense when, in fact, it doesn’t.</p>

<p>To help address that, Narrator will soon sport a “Developer Mode” that enables you to blank out a single app (such as the Edge browser window) so you can experience it without any visual access to the UI. (You can also use it for installed and hosted apps.)</p>

<p>{% youtube lJ-4AVxAIsc %}</p>

<p>Here we see the HTML5accessibility site again. If I flip on Developer Mode in Narrator, the Edge browser window goes black and I can see where the focus carat moves (the blue box), but I can’t see the design. For diagnostic purposes, the contents being read by Narrator are also presented as text on the screen in the position of the element (which can help with identifying where the issue was when you come back out of Developer Mode).</p>

<p>Microsoft is committed to improving the accessibility, not only of its own products, but of the Web as a whole. These two tools are only a few of the many ways we are doing that today.</p>

<p>Obviously, part of that is continuing to evolve and improve the accessibility of the Web for users browsing in Edge, whether they are using Narrator or other screen readers like Jaws or NVDA.</p>

<p>But, in addition to that, Microsoft—in partnership with Carnegie Mellon and Stanford, Adobe, AT&amp;T, Dropbox, Facebook, Intuit, LinkedIn, and Yahoo—helped launch <a href="http://teachaccess.org/">TeachAccess</a>. This site is an effort to address the “lack of awareness and understanding of basic accessibility issues, concepts and best practices” in the world of <abbr aria-label="computer science">CS</abbr> and <abbr aria-label="human-computer interaction">HCI</abbr> education. If successful, which I sincerely hope it is, it will help address the dire need we have for a more accessibility-aware workforce building for the Web.</p>

<p>Similarly, <a href="https://www.microsoft.com/design">Microsoft Design</a> has shared <a href="https://www.microsoft.com/design/practice">their fantastic set of resources for improving the inclusiveness of design</a>. They have created a guide as well as a set of activities you can use to get your team into the <a href="http://www.inclusivedesigntoolkit.com/betterdesign2/whatis/whatis.html">Inclusive Design</a> mindset.</p>

<p>And in the not too distant future, we’ll be publishing a series of in-depth posts about accessibility on the <a href="https://blogs.windows.com/msedgedev/">Microsoft Edge Dev Blog</a>. These will tackle topics like how we re-architected Edge for better ARIA support and name computation, working with HTML5 accessibility to improve the tests, and how we can enable automated testing in order to discover accessibility regressions before they make it into production.</p>

<p>We do this because, with accessibility in mind, we can improve the lives of billions of people. Friends, family, neighbors, and complete strangers, all of whom deserve the opportunity to access the products we create regardless of the different ways we experience the world.</p>

<p>Ultimately “accessibility” is not about disabilities or the technologies we use to address them, <strong>it’s about people</strong>. Sure, we’ll make it easier to look up movie times and purchase tickets to see the latest Transformers debacle, but we’ll also empower the nearly 900 million people globally—over 60% of whom are female—that are illiterate by enabling our sites to be used purely via voice, even translated in real-time into their native language and dialect.</p>

<p>We will create new opportunities for the poor and disadvantaged to participate in a world that has largely excluded them. You may not be aware, but 80% of Fortune 500 companies—think Target, Walmart—only accept job applications online or via computers.</p>

<p>We will enable people who have limited computer skills or who struggle with reading to apply for jobs with these companies.</p>

<p>We will empower immigrants to read lease agreements and postal mail in languages they haven’t fully grasped yet.</p>

<p>We will enable people with visual disabilities to vote, even on paper ballots, without human assistance.</p>

<p>We can help bridge the digital divide and the literacy gap. We can create opportunities for people to better their lives and the lives of their families. We have the power to create more equity in this world than most of us have ever dreamed.</p>

<p>This is an incredibly exciting time, not just for accessibility, not just for user experience, not just the Web, but for the world! I can’t wait to see how awesome you make it!</p>

<p>Thank you!</p>

<hr />

<p><em>You can watch (or listen) to me present this talk (albeit with a bit of technical difficulty) <a href="https://channel9.msdn.com/Events/WebPlatformSummit/edgesummit2016/ES1612">over on the Channel 9 website.</a></em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Learn From the Past, Enhance for the Future]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/learn-from-the-past-enhance-for-the-future/"/>
    <updated>2016-03-04T17:33:57-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/learn-from-the-past-enhance-for-the-future</id>
    <content type="html"><![CDATA[<p><em>I had the great pleasure of delivering the closing keynote for the first EnhanceConf. I wanted to talk about voice and the future of “headless” user interfaces. Here’s what I had to say.</em></p>

<!-- more -->

<hr />

<p>Early last year, <a href="/notebook/how-to-apply-progressive-enhancement-when-javascript-seems-like-a-requirement/">a cry for help on Stack Overflow drew my attention</a>:</p>

<blockquote>
  <p>I’ve been trying to make my site … work fully without JavaScript, however, I’ve found myself in situations where I can’t honestly think how I would do some features without it.</p>
</blockquote>

<p>The submitter, JamHam, is certainly not alone in feeling this way. The ways we build websites change all the time. When I started out, it was pretty simple: you had HTML. Lots and lots of HTML. We also had Java applets, then Shockwave and Flash. Then we got some very basic stylesheet support. Then JavaScript.</p>

<p>As the years pressed on, the three major technologies underpinning the Web—HTML, CSS, and JavaScript—evolved and became even more powerful.</p>

<p>Things coalesced for a while in the early oughts before Jesse James Garrett re-christened a relatively obscure Microsoft creation, <code>XMLHttpRequest</code>, “AJAX” and set countless designers hearts aflutter with the promise of banishing the page refresh. At the heart of this revolution was JavaScript, and companies began betting their entire Web presence on its availability. Most learned that wasn’t such a good idea and began using it as an enhancement to the experience rather than a requirement.</p>

<p>After Ajax, there was HTML5, CSS3, and a host of new JavaScript APIs… the JavaScript frameworks—Angular, Knockout, Backbone, Ember, React… The ways we can create Web products just keep changing; sometimes slowly, but more often than not at such a speedy clip it leaves my head spinning.</p>

<p>The one thing I’ve learned however, being an “old man” in Web terms, is that web design is cyclical, just like everything else. <strong>The challenges we face building web products today are not new challenges.</strong> Moreover, the lessons we learned building similar products in the “Web 1.0” days pay dividends today and will continue to do so in the future.</p>

<p>When I started out on the Web, I had a 28.8 <abbr aria-label="kilobits per second">kbit/s</abbr> modem, but still had to support users on 14.4 <abbr aria-label="kilobits per second">kbit/s</abbr> connections. That’s half the speed I was used to running at. That may have been 20 years ago, but the lessons I learned about streamlining my HTML, optimizing images, and minimizing downloads has helped me immeasurably when dealing with high-latency mobile networks and excruciatingly slow “broadband” connections.</p>

<p>(I’m looking at you, every hotel ever.)</p>

<p>When I started out on the Web, I had an 800x600 monitor, but still had to support 640x480 screen resolutions. I learned the importance of prioritizing content long before media queries and flexbox enabled us to adapt our layouts on the fly. And while our computer screens keep getting bigger, mobile devices and wearables present the very same challenges I was tackling with 640x480, but in even tighter confines.</p>

<figure id="figure-2016-03-04-01">
<img src="https://www.aaron-gustafson.com/i/posts/2016-03-04/01.gif" alt="Screen sizes changing over time." />
</figure>

<p>When I started out on the Web, there was no JavaScript. All calculations, data processing, and dynamic functionality had to be handled by the server. I learned how to process web forms in Perl, later trading in my CGI scripts for PHP, Ruby, and Python. And while the vast majority of our users today have JavaScript baked into their browsers, I still rely on server-side fallbacks because I recognize that we don’t control the execution environment on the open Web.</p>

<blockquote>
  <p>The Web is the most hostile software engineering environment imaginable.<br />— Douglas Crockford</p>
</blockquote>

<p>You’re a savvy bunch, so I’m sure none of this is news to you, but I wanted to set the stage for what I’m really here to talk about. There’s a new cycle about to hit us and chances are you might not be thinking about it yet: Voice.</p>

<h2 id="i-the-headless-ui">I: The Headless UI</h2>

<p>Science fiction has often been a strong predictor of our technological future. HAL 9000 from <em>2001: A Space Odyssey</em> is probably the most (in)famous example of a computer that interacts with its users largely via voice. As a concept, the “talking computer” has appeared time and time again in space-age fiction—everything from <em>Red Dwarf</em> to <em>Interstellar</em>.</p>

<p>To function in the real world like they do on TV and in the movies, computers need two capabilities: Natural language processing (to understand what we say) and speech synthesis (to communicate, aurally, back to us).</p>

<figure id="figure-2016-03-04-02">
<img src="https://www.aaron-gustafson.com/i/posts/2016-03-04/02.gif" alt="Visual of a human and a computer conversing." />
</figure>

<p>Natural language processing has its roots in the 1950s, but many of these early speech models were limited because they were built around a series of hard-coded rules that the computers followed. In the 1980s, however, machine learning and real-time statistical analysis became possible.</p>

<p>As hardware capabilities continued to improve and computers became more powerful, they got better at recognizing the words we were saying to them. Eventually, and with enough processing power, they also began to assign meaning to words and could react accordingly.</p>

<p>As the years marched on, the overhead required to enable our projects to listen to our users has dropped significantly.</p>

<p>Listening is great, but true communication is bidirectional. Humans have been experimenting with speech synthesis since the late 1700s, but it wasn’t until the 1980s that we got a decent result though. By the 1990s, reasonably intelligible text-to-speech software was being rolled out alongside most operating systems as a core component of their assistive technology offerings: The “screen reader”. At present, screen readers are probably the best indicator of what the future of voice interaction will sound like.</p>

<p>When combined, the ability of a computer to listen and respond gave rise to virtual personal assistants like Siri, Cortana, Alexa, and more.</p>

<p>Over time, our customers will become more accustomed to and reliant on voice-based interactions with their computers and the Web. Enabling them to complete critical tasks without a visual user interface will be crucial for the long-term success of our Web-based products.</p>

<p>So how do you design a “headless” UI? That’s easy: You design the conversation.</p>

<h2 id="ii-interface-is-conversation">II: Interface is Conversation</h2>

<p>Let’s take a trip back in time to one of the earliest computer games: Zork. Zork was written between 1977 and 1979. It’s a text-based adventure game that operates a lot like a game of <em>Dungeons &amp; Dragons</em>—with the program serving the role of gamemaster.</p>

<blockquote>
  <p>West of House<br /> You are standing in an open field west of a white house, with a boarded front door.<br /> There is a small mailbox here.<br /><br />&gt; <strong>open mailbox</strong></p>
</blockquote>

<p>As you move from location to location throughout the game, the program describes the environment and notes objects and people you can interact with. You type what you want to do and the program tells you the results of your actions.</p>

<p>As this was the early days of computer gaming, you might think Zork’s interactions would be simple noun-verb combinations—”kill troll”—but Zork was more sophisticated than that. Its parser was could understand far more complex commands like “hit the troll with the Elvish sword”. This made the experience far more natural, as if you were playing a table top game with friends.</p>

<p>Whether Zork or a webpage, <strong>every interface is a conversation</strong>—we engage our users directly in an effort to inform them, entertain them, or persuade them to act in a particular way. How this conversation goes directly affects the experience our users have.</p>

<p>Let’s look at a few web page and interface component types to identify the kinds of conversations we trying to have with our users in each:</p>

<ul>
  <li><strong>Homepage</strong><br /> We’ve just met and I’m explaining what you can do on my site (and, in some cases, why it matters).</li>
  <li><strong>Contact Form</strong><br /> You’re asking or telling me something. I want to help you. It’s common courtesy for me to let you know how long it may take me to get back to you with a response; and for me to abide by that.</li>
  <li><strong>Product Page</strong><br /> I’m explaining what a particular object or service is, what it does, and how it will benefit you. I should “show” you why something is great rather than “tell”-ing you that it is because you’re immune to salesy <abbr aria-label="bullshit">BS</abbr>.</li>
  <li><strong>Status Update</strong><br /> I may prompt you with a question, but I’m here to listen. The floor is yours. (But I’m probably mining what you say for data so I can market to you later.)</li>
</ul>

<p>When we approach interfaces as conversations, we humanize our products and improve our users’ experiences. When we don’t, things can fall apart quickly…</p>

<p>Over the 2011 holidays, Facebook users were uploading photos like crazy. In the span of a few days, Facebook processed more photo uploads than are contained in the entirety of Flickr. Seriously, that’s a lot of photos.</p>

<p>One unintended consequence of this deluge of photo uploads was a significant uptick in people asking Facebook to remove specific ones. Facebook received millions of these “photo reports”, but they made no sense: Moms holding babies reported for harassment, pictures of puppies reported for hate speech, and so on. Roughly 97% of these photo reports were dramatically mis-categorized.</p>

<p>Facebook’s engineers reached out to some of the users who had reported these photos to get a bit more background regarding their submissions. At the time Facebook’s photo reporting interface provided a list of reasons users could choose from if they wanted a photo removed, but, as Facebook soon discovered, many of the reports were made because users didn’t want the photo posted for reasons other than those provided. In some cases, it was because they didn’t like how they looked in the photo. In others, it was because the photo was of an ex-partner or even a beloved pet they’d shared with an ex-boyfriend or ex-girlfriend.</p>

<p>The existing photo reporting tool had not done a good job of accounting for these more personal reasons for wanting a photo removed, so the Facebook engineers went to work. They added a step that asked <em>How does this photo make you feel?</em> The options were simple:</p>

<ul>
  <li>Embarrassing</li>
  <li>Upsetting</li>
  <li>Saddening</li>
  <li>Bad Photo</li>
  <li>Other</li>
</ul>

<p>The “other” option also provided a free-response text field to fill in.</p>

<p>With this system in place, they found that 50% of reporters who answered the new question chose one of the provided options. That was pretty helpful, but there was still a problem: 34% of the “other” respondents were writing “It’s embarrassing” in the blank rather than choosing the “embarrassing” option already provided.</p>

<p>What the Facebook team realized was that people were not identifying with the “embarrassing” text (or may have even thought it was referring to them, rather than assuming an implied “It’s”). A subtle shift in language was needed, so they changed the label to <em>Please describe the photo</em> and they updated the options to mirror how people actually talk:</p>

<ul>
  <li>It’s embarrassing</li>
  <li>It’s a bad photo of me</li>
  <li>It makes me sad</li>
</ul>

<p>With this subtle change, they were able to increase the percentage of photo reporters who chose one of the options provided to a whopping 78%.</p>

<p>Words matter. Even in something as simple and banal as a form, the words we choose set the tone for our users’ experiences and often have an affect on what they do… or fail to do.</p>

<p>The text of our interfaces—especially form labels and responses—is just one small part of the content picture, but it’s a perfect example of how easy it can be to overlook conversation in our interfaces. There are many other types of content like product descriptions, marketing copy, legal statements, visualizations, video, audio, and more. Content is where experience begins. It’s the core that we seek to progressively enhance. It’s also the foundation upon which the voice-based experiences of the future will be based.</p>

<p>The more time and consideration we put into how our interfaces read, the better-positioned we will be to succeed in the future of headless UIs. Once stripped of its beautifully-crafted, responsive layout, engaging animations, and artful illustrations, does your site hold up?</p>

<hr />

<p>Back in 2006, <a href="http://www.dustindiaz.com/naked-day/">Dustin Diaz proposed CSS Naked Day</a>—a day when sites could be stripped of their visual design to showcase their content, semantics, and organization.</p>

<blockquote>
  <p>It will be a test case to see how usable your website is to others without a “design”.<br /> —Dustin Diaz</p>
</blockquote>

<p>“Design”, as Dustin was refering to it, is the visual design of a site, but design is not solely concerned with visual representations. Diving into etymology for a moment here, <em>design</em> comes from the Latin <i lang="la">designare</i> meaning “to mark out or indicate”. The purpose of design is not to make something pretty, it’s to clarify.</p>

<p>If the words we use form the basis of the conversations we have with our users, the semantics we employ clarify that meaning. Choosing elements with semantic value enriches our content, illuminating the meaning and intent of our words in order to overcome the limitations of text and bring it up to par with spoken language. After all, they may look the same visually, but there’s a big difference between these two statements:</p>

<p>{% gist 6f5b7c0f0c072631a908 different-meanings.html %}</p>

<p>Beyond using markup to clarify the intent of the words we write, we can use it to spell out relationships that are often represented visually. Dustin described one way we do this as part of the impetus for CSS Naked Day (emphasis mine):</p>

<blockquote>
  <p>In the spirit of promoting Web Standards along with good semantic markup and <em>proper hierarchy structures</em></p>
</blockquote>

<p>By “proper hierarchy”, Dustin is talking about the document outline. A document outline is created through use of heading elements (<code>h1</code>–<code>h6</code>). It provides a easy way to review the organization of our web pages and validate our source order decisions. It also helps us ensure the flow works, which is incredibly important in any conversation. It helps us get to the point, streamline our content, and remove distractions… all of which are a sign of respect to our users.</p>

<p>None of this is news, of course, content strategists have been recommending that we streamline our content since the dawn of the Web. Sadly, many folks didn’t heed that advice until they were forced to confront the often infuriating world of mobile. Smaller screens required focused content.</p>

<p>When Luke Wroblewski coined “mobile first”, he told us to focus on the core purpose each and every page. He was, in essence, telling us to focus on the conversation we are having with our users. This approach pays huge dividends on small screens, but when it comes to voice-based interactions, “the page” doesn’t really exist. Experience is the sum of each individual interaction. As part of their <a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit">Alexa Skills Kit</a>, <a href="https://developer.amazon.com/public/solutions/alexa/alexa-skills-kit/docs/alexa-skills-kit-voice-design-best-practices">Amazon offers a ton of recommendations for designing for voice</a>, many of which happen to be equally useful for sighted users.</p>

<h3 id="write-for-people">Write for People</h3>

<p>We don’t author content for ourselves. We write for others. If what we write frustrated or alienates our users, we’ve failed at our job. In their profoundly helpful book <a href="http://www.amazon.com/gp/product/0321988191/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0321988191&amp;linkCode=as2&amp;tag=easydesign-20&amp;linkId=5INOUNG72ODCWZQV"><cite>Nicely Said</cite></a>, Nicole Fenton and Kate Kiefer Lee offer numerous suggestions for how to write with the reader in mind:</p>

<blockquote>
  <ul>
    <li>Be clear.</li>
    <li>Be concise.</li>
    <li>Be honest.</li>
    <li>Be considerate.</li>
    <li>Write how you speak.</li>
  </ul>
</blockquote>

<p>They also make the recommendation that you read your work aloud. As we head into the world of voice-based interactions, that’s beta testing!</p>

<h3 id="avoid-technical-and-legal-jargon">Avoid Technical and Legal Jargon</h3>

<p>When we are writing for our readers, we need to be familiar with their level of domain knowledge so we don’t frustrate or alienate them. For example, if you track error codes for issues on your site, send them to <em>your developers</em>, but never present them to a user.</p>

<figure id="figure-2016-03-04-03">
{% adaptive_image /i/posts/2016-03-04/03.png %}
</figure>

<p>Similarly, we should avoid legalese and write in plain language. Medium has done a great job of this with <a href="https://medium.com/policy/medium-terms-of-service-9db0094a1e0f#.mgexdk816">their Terms of Service</a>.</p>

<figure id="figure-2016-03-04-04">
{% adaptive_image /i/posts/2016-03-04/04.png %}
</figure>

<h3 id="when-requesting-feedback-make-it-clear-that-the-user-needs-to-respond"><strong>When Requesting Feedback, Make It Clear that the User Needs to Respond</strong></h3>

<p>In perhaps the most common form example, consider the label “First Name”. It’s not terribly conversational and doesn’t beg for a response. Labels like “What is your first name?” make it clear the user should respond.</p>

<p>{% gist 6f5b7c0f0c072631a908 better-labels.html %}</p>

<figure id="figure-2016-03-04-05">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3" type="audio/mpeg;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/05.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>Similarly, when there’s an error, notify them of the error and, if possible, give them some clues on how to fix it.</p>

<p>{% gist 6f5b7c0f0c072631a908 field-error.html %}</p>

<figure id="figure-2016-03-04-06">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/06.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<h3 id="when-asking-a-user-to-choose-clearly-present-the-options"><strong>When Asking a User to Choose, Clearly Present the Options</strong></h3>

<p>This comes into play often when dealing with forms. Ensuring radio and checkbox controls are properly associated with their labels is critical.</p>

<p>{% gist 6f5b7c0f0c072631a908 radio-label.html %}</p>

<p>You can also use the <code>fieldset</code> and <code>legend</code> elements to group the related controls, but be sure to make the <code>legend</code> focusable or associate it with the first focusable form control in order to ensure the question is read out.</p>

<p>{% gist 6f5b7c0f0c072631a908 fieldset.html %}</p>

<figure id="figure-2016-03-04-07">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/07.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<p>We should strive for the same sort of clarity when presenting navigation options. The HTML5 <code>nav</code> element enables us to semantically identify an area of the page being used for navigation. It does not, however, identify the <code>nav</code> element as being for navigation when encountered naturally in the flow of the document. For that reason, it can be useful to provide an textual introduction to the section, even if you choose to visibly hide it. You might even consider expanding the text of your navigation items to provide additional context.</p>

<p>{% gist 6f5b7c0f0c072631a908 navigation.html %}</p>

<figure id="figure-2016-03-04-08">
<audio controls="">
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" />
<source src="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3" type="audio/mpeg; codecs=&quot;mp3&quot;" />
<p>Listen to this <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.mp3">as an MP3</a> or <a download="" href="https://www.aaron-gustafson.com/i/posts/2016-03-04/08.ogg">as an OGG</a> audio file.</p>
</audio>
</figure>

<h3 id="prompts-should-be-short-while-still-being-clear">Prompts Should be Short, While Still Being Clear.</h3>

<p>In <a href="https://www.stmarys-ca.edu/sites/default/files/attachments/files/On_The_Method_of_Theoretical_Physics.pdf">a 1933 lecture at Oxford</a>, Albert Einstein famously said</p>

<blockquote>
  <p>It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.</p>
</blockquote>

<p>Or, as <a href="https://books.google.com/books?id=prDfAFjet9cC&amp;lpg=PR7&amp;ots=PA9rRog4cr&amp;dq=How%20a%20%E2%80%98Difficult%E2%80%99%20Composer%20Gets%20That%20Way&amp;pg=PA230#v=onepage&amp;q&amp;f=false">Roger Sessions paraphrased it</a></p>

<blockquote>
  <p>Everything should be as simple as it can be but not simpler.</p>
</blockquote>

<p>Clear and concise writing is the hallmark of great content. We need to resist the urge to write for writing’s sake. We write in the service our audience, not for ourselves.</p>

<p>Government websites are some of the worst offenders in this area. Consider this lovely passage:</p>

<blockquote>
  <p>Heavy rains throughout most of the State have given an optimistic outlook for lessened fire danger for the rest of the season. However, an abundance of lightning maintains a certain amount of hazard in isolated areas that have not received an excessive amount of rain.</p>
</blockquote>

<p>It could be written far more clearly as</p>

<blockquote>
  <p>Heavy rains throughout most of the State have lessened fire danger for the rest of the season. However, lightning threatens isolated dry areas.</p>
</blockquote>

<p>Here in the UK, the Government Digital Service has made great strides overhauling excruciatingly painful content and making it easier to read and understand. One such example is <a href="https://gds.blog.gov.uk/2014/07/28/doing-the-hard-work-to-make-things-simple/">their overhaul of the Accelerated Possession process</a> that allows landlords to evict a tenant.</p>

<p>The original paper form asked for the address like this</p>

<blockquote>
  <p>The claimant seeks an order that the defendant(s) give possession of:<br /> (If the premises of which you seek possession are part of a building identify the part eg. Flat 3, Rooms 6 and 7)</p>
</blockquote>

<p>Before requesting the type of property concerned</p>

<blockquote>
  <p>(‘the premises’) which is<br /> ☐ a dwelling house<br /> ☐ part of a dwellinghouse</p>
</blockquote>

<figure id="figure-2016-03-04-09">
{% adaptive_image /i/posts/2016-03-04/09.png %}
</figure>

<p>Clear and to the point, right?</p>

<p>The GDS went to work and streamlined the process in plain language:</p>

<blockquote>
  <p>What kind of property do you want to take back?<br /> ◎ A self-contained house, flat or bedsit<br /> ◎ Room or rooms in a property.<br /> Tenants may share kitchen or bathroom</p>
</blockquote>

<p>Then they allow you to lookup the property or manually enter the address.</p>

<figure id="figure-2016-03-04-10">
{% adaptive_image /i/posts/2016-03-04/10.png %}
</figure>

<p>While not specifically designed for the future of headless UIs, this form is prepared for their eventuality.</p>

<h3 id="ask-only-necessary-questions">Ask Only Necessary Questions</h3>

<p>We show our users respect by respecting their time. Obviously straightforward, brief writing is one way we do that, but another is to reduce the time it takes to complete a task. Many forms are brimming with fields to be filled in. In some cases, the vast majority are purely optional. And while it may be easy to spot the required fields visually, bypassing them in an aural interface can be incredibly difficult.</p>

<figure id="figure-2016-03-04-11">
{% adaptive_image /i/posts/2016-03-04/11.jpg %}
</figure>

<p>User experience designers have been pushing for simplified forms since… well, as long as I can remember. Users appreciate them, they tend to result in better data, and they also tend to convert better than long forms. And when it comes to voice-based interactions, they will become a necessity. No one is going to want to spend 15 minutes working their way through a 15 question registration form when all that’s required is their email address and for them to choose a password.</p>

<figure id="figure-2016-03-04-12">
{% adaptive_image /i/posts/2016-03-04/12.jpg %}
</figure>

<p>On a similar note, we should avoid slicing fields into multiple parts if at all possible. For instance, you still see fields like this one, asking for a US phone number, quite often:</p>

<figure id="figure-2016-03-04-13">
{% adaptive_image /i/posts/2016-03-04/13.png %}
</figure>

<p>When interacting with this construct via voice, a user will be required to supply three separate values. In order to do so, each field would require a label. Even in the States, most developers would only know how to label the first of those three boxes. (They are area code, exchange or central office code, and line number, if you’re interested.)</p>

<p>HTML5 introduced a host of new field types that consolidate phone numbers, dates, times, and other complex data types into single fields. Use them! As an added bonus, most enforce content validation and formatting rules for you automatically.</p>

<h3 id="present-information-in-consumable-pieces">Present Information in Consumable Pieces</h3>

<p>Like computers, we humans have a finite amount of “working memory”. The amount of mental resources required to operate an interface is called its “cognitive load”. When the amount of information we need to process exceeds our capacity to handle it, we can miss important details, have trouble concentrating, and become frustrated.</p>

<p>We deal with cognitive load in GUI design all the time, but in voice-based interactions, there are no visuals to act as signposts and provide reminders about where we are and what we’re doing. This is why it is critical to break complicated tasks down into simpler ones and eliminate excess noise (like non-required fields). We can also reduce cognitive load by chunking search results and other list-type content into small groups, asking the user if they want more before loading and presenting them.</p>

<blockquote>
  <p>The top seller in the garden department is Repel Lemon Eucalyptus Natural Insect Repellent, 4-Ounce Pump Spray</p>
</blockquote>

<blockquote>
  <p>Would you like to hear the rest?</p>
</blockquote>

<h2 id="iii-future-enhancements">III: Future Enhancements</h2>

<p>Paying attention to how our interfaces read is critical to success in the future of voice-based interactions. Thankfully, we already view content as the centerpiece of every progressively enhanced experience. But we can go further.</p>

<p>Both Microsoft and Amazon have given us the tools to voice-enable our websites beyond the HTML we present. Amazon has chosen to do this via a dedicated JSON API, through which we can “teach” Alexa “skills”. Using this API, you can enable your users to access core site functionality through the Echo, FireTV, or any other device that has integrated the Alexa Voice Service.</p>

<p>Microsoft has taken a slightly different approach. Using a relatively simple XML format, they have enabled us to teach Cortana new commands that tie directly into our website.</p>

<p>{% gist 6f5b7c0f0c072631a908 meta.html %}</p>

<p>All we need to do is include a <code>meta</code> tag pointing to an XML file that details the commands (and variations) and, when a user installs the site as a hosted app, Cortana picks up the new commands automatically. Those commands, when issued, can open a specific page or even kick off JavaScript methods in the target page.</p>

<p>{% gist 6f5b7c0f0c072631a908 vcd.xml %}</p>

<hr />

<p>We are just starting to scratch the surface of what’s possible in voice-enabling the Web, but it’s exciting to see how some companies are addressing this opportunity. It’s always interesting when things come full circle and we see how lessons we learned early on in the Web remain applicable, not matter how much or quickly things seem to change. Seeing this pattern repeat time and time again is why I’m so drawn to the philosophy of progressive enhancement; it’s not only concerned with supporting the past… it’s setting us up for success in the future.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Affirming User Choice With Checkboxes]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/affirming-user-choice-with-checkboxes/"/>
    <updated>2016-01-06T14:24:31-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/affirming-user-choice-with-checkboxes</id>
    <content type="html"><![CDATA[<p>“Checkbox” form controls have long been a part of software. They enable users to provide a simple binary response—yes or no. On the Web, we often see them in two scenarios: confirmations and multiple choice.</p>

<!-- more -->

<h2 id="confirmation-checkboxes">Confirmation Checkboxes</h2>

<p>Standalone checkboxes are often employed to enable users to affirm a statement, as in <a href="#fig-2016-01-06-01">this example</a> from <a href="https://online.americanexpress.com/myca/logon/us/action/LogonHandler?request_type=LogonHandler&amp;Face=en_US#lilo_loginForm">the American Express login form</a> where a customer can indicate they’d like the site to remember them.</p>

<figure id="fig-2016-01-06-01" class="media-container">{% adaptive_image /i/posts/2016-01-06/01.png %}<figcaption>American Express’ login form offers users the option of being remembered. As that is a binary choice (e.g. yes or no), the checkbox makes sense.</figcaption></figure>

<p>Here’s a simplification of the markup they’re using:</p>

<p>{% gist d281f889a11634b45280 american-express-login-simplified.html %}</p>

<p>This works really well, though I generally prefer to <a href="https://www.aaron-gustafson.com/notebook/labeled-with-love/#an-alternate-approach">combine explicit and implicit labeling</a> to simplify my CSS selectors and broaden their applicability. Here’s how I would rewrite this control:</p>

<p>{% gist d281f889a11634b45280 american-express-login-reimagined.html %}</p>

<p>Regardless of the markup pattern itself, it’s important to note the explicit association of the form control and the <code>label</code> element (using the <code>for</code> attribute). You’ll also notice the input has a straightforward <code>name</code> value which will be submitted to the back end if the user ticks the box.</p>

<p>It’s worth noting that some back-end systems may require a value be submitted for the given variable name (in this case, “REMEMBERME”) regardless of whether the user has ticked the checkbox. If that’s a requirement, you can alter the pattern to use a hidden <code>input</code> as well:</p>

<p>{% gist d281f889a11634b45280 american-express-login-with-hidden.html %}</p>

<p>The source order matters because with matching <code>name</code> values, the final submittable <code>value</code> will always be the one the back-end receives. With this setup, the <code>value</code> of “no” (from the hidden <code>input</code>) will be submitted by default. If the checkbox is ticked, its <code>value</code> is submitted instead, setting REMEMBERME to “yes”.</p>

<h2 id="multiple-choice-checkboxes">Multiple Choice Checkboxes</h2>

<p>The other way we often see checkboxes used is to enable users to choose zero or more items from a collection of options. Consider <a href="#fig-2016-01-06-02">this example</a> from <a href="http://chadevicelab.org/book-time">the Chattanooga Open Device Lab’s reservation form</a>. It allows users to choose the devices they’d like to include in their test matrix:</p>

<figure id="fig-2016-01-06-02" class="media-container">{% adaptive_image /i/posts/2016-01-06/02.png %}<figcaption>In this excerpt from the reservation form on the Chattanooga Open Device Lab website, users can choose to include gaming system options.</figcaption></figure>

<p>The markup they employ is pretty well-organized and straightforward: it’s a list of checkbox options.</p>

<p>{% gist d281f889a11634b45280 chaodl-checkbox-list.html %}</p>

<p>As this is an instance where a user could choose more than one option, the back end needs to be able to capture that information in what’s called an “array”. An array, if you’re unfamiliar, is a collection of values. You’ll notice that the <code>name</code> given to each of these checkbox <code>input</code> elements is the same: “reservation_requested_device[]”. The square brackets (“[]”) at the end of the <code>name</code> are the magic bit that allows the values of <em>each</em> chosen “reservation_requested_device” checkbox to be submitted as the value of “reservation_requested_device”.</p>

<h2 id="applicable-attributes">Applicable Attributes</h2>

<p>Checkbox controls only use a subset of the typical <code>input</code> attributes. In particular, you’ll need to include</p>

<ul>
  <li><code>name</code> - This is the variable name you want to hold the user’s response. As mentioned in <a href="#multiple-choice-checkboxes">the previous section</a>, appending “[]” to the variable name will allow the variable to hold all of the user’s choices as opposed to only the final one.</li>
  <li><code>value</code> - This is the value that should be captured if the user ticks the checkbox.</li>
  <li><code>id</code> - The unique identifier you’re using for the control in order to explicitly associate it with a <code>label</code>.</li>
</ul>

<p>There are a few optional attributes you might consider including as well.</p>

<ul>
  <li><code>checked</code> - Use this null attribute if you want the default state of the checkbox to be ticked. This attribute should be used with caution. <strong>Don’t</strong> use this attribute to automatically check confirmation boxes for things like mailing list opt-ins. <strong>Do</strong> use this attribute when you are displaying sensible default settings or displaying confirmations the user has already made (e.g. in the user’s profile or when re-displaying the form when it has a submission error).</li>
  <li><code>required</code> - Use this to indicate the checkbox must be ticked for the form to be valid. It’s important to note that this attribute is typically only useful in confirmation checkbox scenarios. If you need a user to choose at least one from a multiple choice checkbox collection, it’s useless unless you need them to pick a specific one. To require one (or more) of a multiple choice checkbox group, you currently need to use JavaScript, like <a href="https://github.com/easy-designs/easy-checkbox-required.js">the one the Chattanooga Open Device Lab uses</a>.</li>
</ul>

<h2 id="checkbox-vs-other-controls">Checkbox vs. Other Controls</h2>

<p>Checkboxes excel at allowing users to indicate preference from a pre-defined set of options. But there are other form control types that allow for similar control over user responses. That can make it difficult to decide which element to use.</p>

<h3 id="dropdown-list-select">Dropdown List (<code>select</code>)</h3>

<p>The <code>select</code> element is another tried and true option for allowing users to indicate preference. A simple two-choice <code>select</code> could achieve the same goal as a confirmation checkbox, but it’s a little clunkier. In terms of user interface, <code>select</code> elements require more clicks of your users. They also obscure the complete list of choices from view because only one options is displayed at a time. Their appearance makes them more compact, but can make it difficult to get a complete picture of what choices are available when you can’t see them all.</p>

<p>You can enable multiple choice in a  <code>select</code> element by adding the <code>multiple</code> attribute to it, but depending on the number of <code>option</code> elements, it could also be a little unwieldy. Depending on the size of the <code>select</code> and the number of options, you could also create an inner scroll that could be awkward on certain touch-based devices.</p>

<p>The <code>select</code> element has its place, but should be used sparingly. I’ll go in-depth with <code>select</code> elements in a future post.</p>

<h3 id="choose-one-inputtyperadio">Choose One (<code>input[type=radio]</code>)</h3>

<p>For simple confirmation questions, it’s completely valid to use a radio form control in lieu of a single checkbox. In fact, in some cases, it may offer a more explicit choice for your users. Consider <a href="#fig-2016-01-06-03">this example</a> from <a href="https://order.subway.com">Subway’s online ordering tool</a>.</p>

<figure id="fig-2016-01-06-03" class="media-container">{% adaptive_image /i/posts/2016-01-06/03.png %}<figcaption>In this excerpt from Subway’s online ordering tool, they use a checkbox to confirm the user wants their sandwich toasted.</figcaption></figure>

<p>A checkbox labelled “Fresh Toasted”, isn’t terribly clear. A better approach would be to ask something like “Would you like your sandwich toasted?” with radio controls for “yes” and “no”. Alternately, if they absolutely wanted to keep it as a checkbox, they could use a better label: “Please toast my sandwich”.</p>

<figure id="fig-2016-01-06-04" class="media-container">{% adaptive_image /i/posts/2016-01-06/04.png %}<figcaption>An alternate approach to the Subway interface, using radio controls.</figcaption></figure>

<p>Radio controls have their place, but are not often a one-to-one replacement for checkboxes. I will discuss radio controls in greater depth in another post.</p>

<h2 id="check-em-out">Check ’Em Out</h2>

<p>Checkboxes are an invaluable tool in the form building tool chest. Understanding their purpose and capabilities is key to using them properly and ensuring your forms are usable to the broadest number of users.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Labeled With Love]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/labeled-with-love/"/>
    <updated>2015-11-11T21:05:33-05:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/labeled-with-love</id>
    <content type="html"><![CDATA[<p>Forms exist on pretty much every site on the web in one form or another. They are the primary mechanism by which we gather information from our users.<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> Of course, before anyone can fill out a form, they need to know what it’s asking for. Labeling is key.</p>

<!-- more -->

<p>A few months back, I relayed <a href="https://www.aaron-gustafson.com/notebook/consider-how-your-forms-read/">a story from Facebook</a> about how important the wording of their questions was in getting accurate responses from their users. The words we choose are incredibly important—your interface is a conversation with your users. I highly recommend reading up on that (and <a href="http://www.radiolab.org/story/trust-engineers/">listening to the Radiolab episode</a> that spurred me to write it), but I’m going to spend the remainder of this post talking about the utilitarian aspects of labels and how to use them properly in your forms.</p>

<h2 id="connecting-the-dots">Connecting the Dots</h2>

<p>When you look at a basic form field, you have two bits of information: the field and the label.</p>

<figure id="fig-2015-11-11-01" class="media-container">{% adaptive_image /i/posts/2015-11-11/01.png %}<figcaption>A typical form control: a label and a field.</figcaption></figure>

<p>You could achieve this with a minimum of markup:</p>

<p>{% gist 3585c019108025b2f568 unlabeled-field.html embed %}</p>

<p>The thing is, the text “Your Name” is not associated in any way with the <code>input</code>. Sure, a sighted person would likely be able to tell that that text is associated with the field, but no computer can tell that. And if a computer can’t tell the text and <code>input</code> are associated, your form control is inaccessible to anyone who uses assistive technology like a screen reader. It’s also going to pose a problem in the near-future of “headless UIs” like those hinted at by Cortana, Siri, and the Echo.</p>

<p>Thankfully, establishing a relationship between the two is quite easy using the <code>label</code> element. The most common (and preferable) way to do this is to wrap the labeling text in a <code>label</code> element. Then you create an explicit association with the field using the <code>for</code> attribute, which is an <code>id</code> reference. In other words, the value of the <code>for</code> attribute needs to match the value of the <code>id</code> attribute on the field you want to associate with that <code>label</code>.</p>

<p>{% gist 3585c019108025b2f568 labeled-field.html embed %}</p>

<p>With that markup in place, the programmatic connection between the elements is made and the results speak for themselves: When you focus the field, the contents of the <code>label</code> are read out.</p>

<p>{% youtube WR4_MAjalsU %}</p>

<h2 id="an-alternate-approach">An Alternate Approach</h2>

<p>Since I specifically referred to this approach as <em>explicit</em> association, you probably assumed that there’s another kind of association. And you were right: <em>implicit</em> association. Implicit association is created by wrapping a form control and its associated label text in a <code>label</code> element. I like to use this approach with radio and checkbox controls:</p>

<p>{% gist 3585c019108025b2f568 implicitly-labeled-checkbox.html embed %}</p>

<p>It’s worth noting that there’s nothing wrong with explicit association in this context either.</p>

<p>{% gist 3585c019108025b2f568 explicitly-labeled-checkbox.html embed %}</p>

<p>You can even combine the two approaches.</p>

<p>{% gist 3585c019108025b2f568 combo-labeled-checkbox.html embed %}</p>

<p>The reason I like to use implicit association with checkbox and radio controls has to do with ensuring the greatest breadth of support when it comes to styling inputs. For instance, if I set <code>width: 80%</code> on all <code>input</code> elements using a simple <a href="https://developer.mozilla.org/docs/Web/CSS/Type_selectors">type selector</a>, that width would be applied to <em>all</em> <code>input</code> elements, including radio and checkbox controls. In order to prevent radio and checkbox controls from getting rendered at that width, I would need to assign an override value of <code>width: auto</code> to them them specifically. I can do that using <a href="https://developer.mozilla.org/docs/Web/CSS/Attribute_selectors">attribute selectors</a>:</p>

<p>{% gist 3585c019108025b2f568 modern-only.css embed %}</p>

<p>While completely valid, that approach leaves out any browsers that don’t support attribute selection (e.g. IE 6). That may not seem like a deal-breaker in your book, but on the off chance some poor soul happens to be stuck using an out-of-date browser (as many are on mobile), I like to show them a little love. And, thankfully, using the implicit markup pattern for checkboxes and radio controls allows for this quite easily: I just use a <a href="https://developer.mozilla.org/docs/Web/CSS/Descendant_selectors">descendent selector</a> instead.</p>

<p>{% gist 3585c019108025b2f568 universal.css embed %}</p>

<p>This approach results in a greater amount of support and, incidentally, less CSS.</p>

<h2 id="added-benefit-interactivity">Added Benefit: Interactivity</h2>

<p>Obviously, associated labels are great for folks who use screen readers, but they have another benefit: tapping on a <code>label</code> will focus or activate the associated form control.</p>

<figure id="fig-2015-11-11-02" class="media-container"><img src="https://www.aaron-gustafson.com/i/posts/2015-11-11/02.gif" alt="" /><figcaption>Animation showing how clicking a <code>label</code> will focus the associated form control.</figcaption></figure>

<p>This isn’t a game-changer when it comes to standard text fields, but it’s an exceptional affordance when it comes to radio and checkbox controls, especially on mobile, as it vastly increases the tappable region used to activate the control.</p>

<figure id="fig-2015-11-11-03" class="media-container">{% adaptive_image /i/posts/2015-11-11/03.png %}<figcaption>A screenshot of a group of checkbox controls with their labels outlined.</figcaption></figure>

<p>To create incredibly generous tap targets on mobile devices, we can take things a little further. Add padding to the top and bottom of the <code>label</code> to make it bigger and then use negative margins to counter that enlargement and keep the layout as it was before the padding was applied.</p>

<p>{% gist 3585c019108025b2f568 larger-labels.css embed %}</p>

<figure id="fig-2015-11-11-04" class="media-container"><img src="https://www.aaron-gustafson.com/i/posts/2015-11-11/04.gif" alt="" /><figcaption>An animation showing very generous tap targets on a narrow screen.</figcaption></figure>

<p>It’s worth noting that older versions of Internet Explorer only provide the focus/interaction benefit when you use explicit label association. That’s why I like the combo approach of implicit <em>and</em> explicit association for checkbox and radio controls.</p>

<p><ins datetime="2015-12-09" cite="#comment-2374683375">As Dennis Lembrée mentions in the comments below, Dragon’s Naturally Speaking also doesn’t recognize implicit association, which is why it’s incredibly important to use explicit association even if it seems implicit association should suffice.</ins></p>

<h2 id="placeholders-arent-labels">Placeholders Aren’t Labels</h2>

<p>HTML5 ushered in a new option for working with <code>input</code> elements: the <code>placeholder</code> attribute. This declarative attribute makes it possible to offer hint as to the sort of content you were looking for in a field. In <a href="http://caniuse.com/#feat=input-placeholder">supporting browsers</a>, it appears in the field, ghosted back a bit, and disappears when you start typing a response.<sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup></p>

<figure id="fig-2015-11-11-05" class="media-container"><img src="https://www.aaron-gustafson.com/i/posts/2015-11-11/05.gif" alt="" /><figcaption>An animation showing a placeholder in action on <a href="http://webstandardssherpa.com"><cite>Web Standards Sherpa</cite></a>.</figcaption></figure>

<p>Having this natively supported in the browser was a huge boon. For years we’d been using JavaScript to achieve this very effect—albeit typically for label text—in an effort to create more compact forms. Now we get the effect without having to include any additional files or libraries.</p>

<p>Of course, since <code>placeholder</code> implements an existing pattern, it came with baggage. People commonly achieved this effect by (ab)using the <code>value</code> attribute as a fake label. As such, its introduction didn’t do much to increase the accessibility of forms. <em>Form controls need a label</em>. If you want to make your form more compact, you can do that using proper markup and a little clever CSS.</p>

<p>{% gist 3585c019108025b2f568 fancy-example.html embed %}</p>

<p>{% gist 3585c019108025b2f568 fancy-example.css embed %}</p>

<figure id="fig-2015-11-11-06" class="media-container">{% codepen BoGgYM aarongustafson result 112 preview %}</figure>

<p>Mary Lou assembled some beautiful examples of this approach in her <a href="http://tympanus.net/codrops/2015/01/08/inspiration-text-input-effects/">Inspiration for Text Input Effects</a>. I highly recommend you check those out, but here’s a teaser to whet your whistle:</p>

<figure id="fig-2015-11-11-07" class="media-container"><img src="https://www.aaron-gustafson.com/i/posts/2015-11-11/07.gif" alt="" /><figcaption>A fancy, accessible form field and label from Mary Lou’s collection.</figcaption></figure>

<hr />

<p>We don’t have a ton of elements in HTML, which is why it’s important that we properly use the ones we do have. Hopefully this has provided a helpful overview of how to properly label form controls using HTML.</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>When we’re not, you know, tracking them with a <a href="http://arstechnica.com/security/2015/10/verizons-zombie-cookie-gets-new-life/">super cookie</a> or something. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>Browsers typically exhibit two different behaviors here. Some hide the placeholder text as soon as you focus the field, others hide it only when you start typing. Either one works although, admittedly, I favor the text disappearing when you type rather than when the field receives focus. I can see how that approach might confuse some users, I just prefer it because it ensures you see the placeholder. <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Harvard, MIT, and Captioning]]></title>
    <link href="https://www.aaron-gustafson.com/notebook/harvard-and-mit-and-captioning/"/>
    <updated>2015-06-29T14:23:28-04:00</updated>
    <id>https://www.aaron-gustafson.com/notebook/harvard-and-mit-and-captioning</id>
    <content type="html"><![CDATA[<p>The U.S. Department of Justice (DOJ) has published Statements of Interest in two cases brought by the National Association of the Deaf (NAD) against <a href="http://www.ada.gov/briefs/harvard_soi.pdf">Harvard (PDF)</a> and <a href="http://www.ada.gov/briefs/mit_soi.pdf">MIT (PDF)</a>, respectively. The NAD is suing the two universities for violations of Title III of the Americans with Disabilities Act (ADA) and Section 504 of the Rehabilitation Act because the video and audio materials they are making available as part of their online learning offerings are not captioned.</p>

<!-- more -->

<p>The DOJ Statements make it quite clear that</p>

<blockquote>
  <p>Both the ADA and Section 504 currently obligate Harvard to provide effective communication to ensure equal access to its online programming services, and resolution of Plaintiffs’ claim involves a straightforward application of longstanding statutory and regulatory requirements. For more than two decades, federal courts have resolved effective communication claims brought under the ADA and Section 504 in a wide range of contexts, including claims alleging unequal access to goods, benefits and services provided through websites or other electronic media. And the Departments of Justice and Education have routinely required covered entities to ensure equal access to goods, benefits and services, electronic or otherwise, through the provision of captioning or other auxiliary aids or services.</p>
</blockquote>

<p>Also…</p>

<blockquote>
  <p>[T]he Department issued an Advanced Notice of Proposed Rulemaking (“ANPRM”) on Accessibility of Web Information and Services of State and Local Government Entities and Public Accommodations, announcing the Department’s interest in developing more specific requirements or technical standards for  website accessibility. … In the ANPRM, the Department reaffirmed its longstanding position that the ADA applies to websites of public accommodations, and reiterated, consistent with the preamble to the 1991 regulations, that the ADA regulations should be interpreted to keep pace with developing technologies.</p>
</blockquote>

<p>Neither case has been settled yet, but the fact that the DOJ is siding with the NAD will lend more credence to their complaints and will likely result in one or both institutions settling out of court and, eventually, captioning their videos.</p>

<p>Captions are critical for the deaf and hard of hearing as they let them know what’s being said, who is saying it, how it’s being said, and inform them of any other sounds that are germane to the content. Reading captions is the equivalent of hearing with your eyes.</p>

<p>Are your videos captioned? If your content is aimed at a broad audience, it might be worth your time (and even your money) to get them captioned.</p>

<p>No doubt, accurate captioning is time-consuming. There are some ways of automating it (<a href="https://support.google.com/youtube/answer/3038280">YouTube does this</a>, for instance), but there are also services like <a href="https://castingwords.com/">Casting Words</a>, <a href="https://www.rev.com/caption">Rev</a>, and <a href="http://www.3playmedia.com/">3Play Media</a> that will do it for a nominal fee.</p>

<p>It’s worth noting that the HTML <code>video</code> element supports subtitles and captions via <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/track">the <code>track</code> element</a> (<a href="http://www.iandevlin.com/blog/2015/04/html5/html5-video-captions-current-browser-status">browser support</a>, <a href="http://caniuse.com/#search=track">Can I Use data</a>). YouTube also allows you to <a href="https://support.google.com/youtube/answer/2734796">add captions and subtitles to your videos manually</a>. But keep in mind that <a href="http://screenfont.ca/learn/">captions and subtitles are not the same thing</a>; captions need to capture more than just the words that are said.</p>
]]></content>
  </entry>
  
</feed>
